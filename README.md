# ğŸ‡§ğŸ‡© Bangla Sign Language Assistant ğŸ¤Ÿ

This project is a real-time Bangla Sign Language recognition tool that uses a webcam to detect hand gestures, predict the corresponding Bangla alphabet, and provide audio-visual feedback to help users learn sign language.

## ğŸš€ Features

- ğŸ“· Real-time hand landmark detection using MediaPipe
- ğŸ”¤ Bangla alphabet prediction using trained ML model
- ğŸ§ Audio guidance using `gTTS` and `pyttsx3`
- ğŸŒ Web-based frontend (HTML + Jinja2)
- ğŸ§  Model trained with Scikit-learn + Transformers
- ğŸ—£ï¸ NLP support with BNLP Toolkit

## ğŸ›  Technologies Used

- `mediapipe`, `opencv-python`, `scikit-learn`, `transformers`
- `fastapi`, `uvicorn`, `jinja2` for web backend
- `joblib`, `gtts`, `pyttsx3`, `playsound3` for voice feedback
- `bnlp_toolkit`, `bnnumerizer`, `pyspellchecker` for Bangla text processing

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ bangla_sign_server.py     # FastAPI backend
â”œâ”€â”€ templates/index.html      # Web frontend
â”œâ”€â”€ model/trained_model.pkl   # Pretrained sign classifier
â”œâ”€â”€ Dataset/hand_feedback_data.json  # Sign metadata
â”œâ”€â”€ requirements.txt
